digraph {
	graph [size="46.05,46.05"]
	node [align=left fontname=monospace fontsize=10 height=0.2 ranksep=0.1 shape=box style=filled]
	3043498012272 [label="
 ()" fillcolor=darkolivegreen1]
	3043497940192 [label=MeanBackward0]
	3043497939568 -> 3043497940192
	3043497939568 [label=TanhBackward0]
	3043497940672 -> 3043497939568
	3043497940672 [label=AddmmBackward0]
	3043497940720 -> 3043497940672
	3043498012080 [label="fc_layer.4.bias
 (4)" fillcolor=lightblue]
	3043498012080 -> 3043497940720
	3043497940720 [label=AccumulateGrad]
	3043497939808 -> 3043497940672
	3043497939808 [label=LeakyReluBackward0]
	3043497940912 -> 3043497939808
	3043497940912 [label=AddmmBackward0]
	3043497941104 -> 3043497940912
	3043498011888 [label="fc_layer.2.bias
 (256)" fillcolor=lightblue]
	3043498011888 -> 3043497941104
	3043497941104 [label=AccumulateGrad]
	3043497941056 -> 3043497940912
	3043497941056 [label=LeakyReluBackward0]
	3043497941248 -> 3043497941056
	3043497941248 [label=AddmmBackward0]
	3043497941440 -> 3043497941248
	3043498011696 [label="fc_layer.0.bias
 (512)" fillcolor=lightblue]
	3043498011696 -> 3043497941440
	3043497941440 [label=AccumulateGrad]
	3043497941392 -> 3043497941248
	3043497941392 [label=SqueezeBackward1]
	3043497941536 -> 3043497941392
	3043497941536 [label=CatBackward0]
	3043497941728 -> 3043497941536
	3043497941728 [label=SqueezeBackward1]
	3043497941824 -> 3043497941728
	3043497941824 [label=MaxPool2DWithIndicesBackward0]
	3043497941920 -> 3043497941824
	3043497941920 [label=ReluBackward0]
	3043497941968 -> 3043497941920
	3043497941968 [label=CudnnBatchNormBackward0]
	3043497942112 -> 3043497941968
	3043497942112 [label=ConvolutionBackward0]
	3043497942400 -> 3043497942112
	3043497942400 [label=ReluBackward0]
	3043497942544 -> 3043497942400
	3043497942544 [label=CudnnBatchNormBackward0]
	3043497942592 -> 3043497942544
	3043497942592 [label=ConvolutionBackward0]
	3043497942880 -> 3043497942592
	3043497942880 [label=ReluBackward0]
	3043497943024 -> 3043497942880
	3043497943024 [label=CudnnBatchNormBackward0]
	3043497943072 -> 3043497943024
	3043497943072 [label=ConvolutionBackward0]
	3043497943360 -> 3043497943072
	3043497943360 [label=CatBackward0]
	3043497943504 -> 3043497943360
	3043497943504 [label=UnsqueezeBackward0]
	3043497943600 -> 3043497943504
	3043497943600 [label=CatBackward0]
	3043497943648 -> 3043497943600
	3043497943648 [label=SqueezeBackward1]
	3043497943792 -> 3043497943648
	3043497943792 [label=MaxPool2DWithIndicesBackward0]
	3043497943936 -> 3043497943792
	3043497943936 [label=ReluBackward0]
	3043497944080 -> 3043497943936
	3043497944080 [label=CudnnBatchNormBackward0]
	3043497944224 -> 3043497944080
	3043497944224 [label=ConvolutionBackward0]
	3043497944512 -> 3043497944224
	3043497944512 [label=ReluBackward0]
	3043497944656 -> 3043497944512
	3043497944656 [label=CudnnBatchNormBackward0]
	3043497944704 -> 3043497944656
	3043497944704 [label=ConvolutionBackward0]
	3043497944992 -> 3043497944704
	3043497944992 [label=ReluBackward0]
	3043497945136 -> 3043497944992
	3043497945136 [label=CudnnBatchNormBackward0]
	3043497945184 -> 3043497945136
	3043497945184 [label=ConvolutionBackward0]
	3043497945472 -> 3043497945184
	3043497945472 [label=CatBackward0]
	3043497860624 -> 3043497945472
	3043497860624 [label=GroupingOperationBackward]
	3043497945664 -> 3043497860624
	3043497945664 [label=CatBackward0]
	3043497945760 -> 3043497945664
	3043497945760 [label=SqueezeBackward1]
	3043497945808 -> 3043497945760
	3043497945808 [label=MaxPool2DWithIndicesBackward0]
	3043497945952 -> 3043497945808
	3043497945952 [label=ReluBackward0]
	3043497946096 -> 3043497945952
	3043497946096 [label=CudnnBatchNormBackward0]
	3043497946240 -> 3043497946096
	3043497946240 [label=ConvolutionBackward0]
	3043497946528 -> 3043497946240
	3043497946528 [label=ReluBackward0]
	3043497946672 -> 3043497946528
	3043497946672 [label=CudnnBatchNormBackward0]
	3043497946720 -> 3043497946672
	3043497946720 [label=ConvolutionBackward0]
	3043497947008 -> 3043497946720
	3043497947008 [label=ReluBackward0]
	3043497947152 -> 3043497947008
	3043497947152 [label=CudnnBatchNormBackward0]
	3043497947200 -> 3043497947152
	3043497947200 [label=ConvolutionBackward0]
	3043497947488 -> 3043497947200
	3043497947488 [label=CatBackward0]
	3043497860352 -> 3043497947488
	3043497860352 [label=GroupingOperationBackward]
	3043497947680 -> 3043497860352
	3043497947680 [label=CatBackward0]
	3043497947776 -> 3043497947680
	3043497947776 [label=SqueezeBackward1]
	3043497947824 -> 3043497947776
	3043497947824 [label=MaxPool2DWithIndicesBackward0]
	3043497947968 -> 3043497947824
	3043497947968 [label=ReluBackward0]
	3043497948112 -> 3043497947968
	3043497948112 [label=CudnnBatchNormBackward0]
	3043497948256 -> 3043497948112
	3043497948256 [label=ConvolutionBackward0]
	3043497948544 -> 3043497948256
	3043497948544 [label=ReluBackward0]
	3043497948688 -> 3043497948544
	3043497948688 [label=CudnnBatchNormBackward0]
	3043497948736 -> 3043497948688
	3043497948736 [label=ConvolutionBackward0]
	3043497949024 -> 3043497948736
	3043497949024 [label=ReluBackward0]
	3043497949168 -> 3043497949024
	3043497949168 [label=CudnnBatchNormBackward0]
	3043497949216 -> 3043497949168
	3043497949216 [label=ConvolutionBackward0]
	3043497949504 -> 3043497949216
	3043498004688 [label="SA_modules.0.mlps.0.0.weight
 (32, 3, 1, 1)" fillcolor=lightblue]
	3043498004688 -> 3043497949504
	3043497949504 [label=AccumulateGrad]
	3043497949072 -> 3043497949168
	3043498004784 [label="SA_modules.0.mlps.0.1.weight
 (32)" fillcolor=lightblue]
	3043498004784 -> 3043497949072
	3043497949072 [label=AccumulateGrad]
	3043497949312 -> 3043497949168
	3043498004880 [label="SA_modules.0.mlps.0.1.bias
 (32)" fillcolor=lightblue]
	3043498004880 -> 3043497949312
	3043497949312 [label=AccumulateGrad]
	3043497948976 -> 3043497948736
	3043498005264 [label="SA_modules.0.mlps.0.3.weight
 (32, 32, 1, 1)" fillcolor=lightblue]
	3043498005264 -> 3043497948976
	3043497948976 [label=AccumulateGrad]
	3043497948592 -> 3043497948688
	3043498005360 [label="SA_modules.0.mlps.0.4.weight
 (32)" fillcolor=lightblue]
	3043498005360 -> 3043497948592
	3043497948592 [label=AccumulateGrad]
	3043497948832 -> 3043497948688
	3043498005456 [label="SA_modules.0.mlps.0.4.bias
 (32)" fillcolor=lightblue]
	3043498005456 -> 3043497948832
	3043497948832 [label=AccumulateGrad]
	3043497948496 -> 3043497948256
	3043498005840 [label="SA_modules.0.mlps.0.6.weight
 (64, 32, 1, 1)" fillcolor=lightblue]
	3043498005840 -> 3043497948496
	3043497948496 [label=AccumulateGrad]
	3043497948208 -> 3043497948112
	3043498005936 [label="SA_modules.0.mlps.0.7.weight
 (64)" fillcolor=lightblue]
	3043498005936 -> 3043497948208
	3043497948208 [label=AccumulateGrad]
	3043497948352 -> 3043497948112
	3043498006032 [label="SA_modules.0.mlps.0.7.bias
 (64)" fillcolor=lightblue]
	3043498006032 -> 3043497948352
	3043497948352 [label=AccumulateGrad]
	3043498012368 -> 3043497860352 [dir=none]
	3043498012368 [label="
 (16, 256, 64)" fillcolor=orange]
	3043498013424 -> 3043497860352 [dir=none]
	3043498013424 [label="
 (16, 64, 512)" fillcolor=orange]
	3043497947440 -> 3043497947200
	3043498006416 [label="SA_modules.1.mlps.0.0.weight
 (64, 67, 1, 1)" fillcolor=lightblue]
	3043498006416 -> 3043497947440
	3043497947440 [label=AccumulateGrad]
	3043497947056 -> 3043497947152
	3043498006512 [label="SA_modules.1.mlps.0.1.weight
 (64)" fillcolor=lightblue]
	3043498006512 -> 3043497947056
	3043497947056 [label=AccumulateGrad]
	3043497947296 -> 3043497947152
	3043498006608 [label="SA_modules.1.mlps.0.1.bias
 (64)" fillcolor=lightblue]
	3043498006608 -> 3043497947296
	3043497947296 [label=AccumulateGrad]
	3043497946960 -> 3043497946720
	3043498006992 [label="SA_modules.1.mlps.0.3.weight
 (64, 64, 1, 1)" fillcolor=lightblue]
	3043498006992 -> 3043497946960
	3043497946960 [label=AccumulateGrad]
	3043497946576 -> 3043497946672
	3043498007088 [label="SA_modules.1.mlps.0.4.weight
 (64)" fillcolor=lightblue]
	3043498007088 -> 3043497946576
	3043497946576 [label=AccumulateGrad]
	3043497946816 -> 3043497946672
	3043498007184 [label="SA_modules.1.mlps.0.4.bias
 (64)" fillcolor=lightblue]
	3043498007184 -> 3043497946816
	3043497946816 [label=AccumulateGrad]
	3043497946480 -> 3043497946240
	3043498007568 [label="SA_modules.1.mlps.0.6.weight
 (128, 64, 1, 1)" fillcolor=lightblue]
	3043498007568 -> 3043497946480
	3043497946480 [label=AccumulateGrad]
	3043497946192 -> 3043497946096
	3043498007664 [label="SA_modules.1.mlps.0.7.weight
 (128)" fillcolor=lightblue]
	3043498007664 -> 3043497946192
	3043497946192 [label=AccumulateGrad]
	3043497946336 -> 3043497946096
	3043498007760 [label="SA_modules.1.mlps.0.7.bias
 (128)" fillcolor=lightblue]
	3043498007760 -> 3043497946336
	3043497946336 [label=AccumulateGrad]
	3043498012656 -> 3043497860624 [dir=none]
	3043498012656 [label="
 (16, 128, 64)" fillcolor=orange]
	3043498014288 -> 3043497860624 [dir=none]
	3043498014288 [label="
 (16, 128, 256)" fillcolor=orange]
	3043497945424 -> 3043497945184
	3043498008144 [label="SA_modules.2.mlps.0.0.weight
 (128, 131, 1, 1)" fillcolor=lightblue]
	3043498008144 -> 3043497945424
	3043497945424 [label=AccumulateGrad]
	3043497945040 -> 3043497945136
	3043498008240 [label="SA_modules.2.mlps.0.1.weight
 (128)" fillcolor=lightblue]
	3043498008240 -> 3043497945040
	3043497945040 [label=AccumulateGrad]
	3043497945280 -> 3043497945136
	3043498008336 [label="SA_modules.2.mlps.0.1.bias
 (128)" fillcolor=lightblue]
	3043498008336 -> 3043497945280
	3043497945280 [label=AccumulateGrad]
	3043497944944 -> 3043497944704
	3043498008720 [label="SA_modules.2.mlps.0.3.weight
 (128, 128, 1, 1)" fillcolor=lightblue]
	3043498008720 -> 3043497944944
	3043497944944 [label=AccumulateGrad]
	3043497944560 -> 3043497944656
	3043498008816 [label="SA_modules.2.mlps.0.4.weight
 (128)" fillcolor=lightblue]
	3043498008816 -> 3043497944560
	3043497944560 [label=AccumulateGrad]
	3043497944800 -> 3043497944656
	3043498008912 [label="SA_modules.2.mlps.0.4.bias
 (128)" fillcolor=lightblue]
	3043498008912 -> 3043497944800
	3043497944800 [label=AccumulateGrad]
	3043497944464 -> 3043497944224
	3043498009296 [label="SA_modules.2.mlps.0.6.weight
 (256, 128, 1, 1)" fillcolor=lightblue]
	3043498009296 -> 3043497944464
	3043497944464 [label=AccumulateGrad]
	3043497944176 -> 3043497944080
	3043498009392 [label="SA_modules.2.mlps.0.7.weight
 (256)" fillcolor=lightblue]
	3043498009392 -> 3043497944176
	3043497944176 [label=AccumulateGrad]
	3043497944320 -> 3043497944080
	3043498009488 [label="SA_modules.2.mlps.0.7.bias
 (256)" fillcolor=lightblue]
	3043498009488 -> 3043497944320
	3043497944320 [label=AccumulateGrad]
	3043497943312 -> 3043497943072
	3043498009872 [label="SA_modules.3.mlps.0.0.weight
 (256, 259, 1, 1)" fillcolor=lightblue]
	3043498009872 -> 3043497943312
	3043497943312 [label=AccumulateGrad]
	3043497942928 -> 3043497943024
	3043498009968 [label="SA_modules.3.mlps.0.1.weight
 (256)" fillcolor=lightblue]
	3043498009968 -> 3043497942928
	3043497942928 [label=AccumulateGrad]
	3043497943168 -> 3043497943024
	3043498010064 [label="SA_modules.3.mlps.0.1.bias
 (256)" fillcolor=lightblue]
	3043498010064 -> 3043497943168
	3043497943168 [label=AccumulateGrad]
	3043497942832 -> 3043497942592
	3043498010448 [label="SA_modules.3.mlps.0.3.weight
 (512, 256, 1, 1)" fillcolor=lightblue]
	3043498010448 -> 3043497942832
	3043497942832 [label=AccumulateGrad]
	3043497942448 -> 3043497942544
	3043498010544 [label="SA_modules.3.mlps.0.4.weight
 (512)" fillcolor=lightblue]
	3043498010544 -> 3043497942448
	3043497942448 [label=AccumulateGrad]
	3043497942688 -> 3043497942544
	3043498010640 [label="SA_modules.3.mlps.0.4.bias
 (512)" fillcolor=lightblue]
	3043498010640 -> 3043497942688
	3043497942688 [label=AccumulateGrad]
	3043497942352 -> 3043497942112
	3043498011024 [label="SA_modules.3.mlps.0.6.weight
 (1024, 512, 1, 1)" fillcolor=lightblue]
	3043498011024 -> 3043497942352
	3043497942352 [label=AccumulateGrad]
	3043497942064 -> 3043497941968
	3043498011120 [label="SA_modules.3.mlps.0.7.weight
 (1024)" fillcolor=lightblue]
	3043498011120 -> 3043497942064
	3043497942064 [label=AccumulateGrad]
	3043497942208 -> 3043497941968
	3043498011216 [label="SA_modules.3.mlps.0.7.bias
 (1024)" fillcolor=lightblue]
	3043498011216 -> 3043497942208
	3043497942208 [label=AccumulateGrad]
	3043497941344 -> 3043497941248
	3043497941344 [label=TBackward0]
	3043497941776 -> 3043497941344
	3043498011600 [label="fc_layer.0.weight
 (512, 1024)" fillcolor=lightblue]
	3043498011600 -> 3043497941776
	3043497941776 [label=AccumulateGrad]
	3043497941008 -> 3043497940912
	3043497941008 [label=TBackward0]
	3043497941680 -> 3043497941008
	3043498011792 [label="fc_layer.2.weight
 (256, 512)" fillcolor=lightblue]
	3043498011792 -> 3043497941680
	3043497941680 [label=AccumulateGrad]
	3043497940624 -> 3043497940672
	3043497940624 [label=TBackward0]
	3043497941488 -> 3043497940624
	3043498011984 [label="fc_layer.4.weight
 (4, 256)" fillcolor=lightblue]
	3043498011984 -> 3043497941488
	3043497941488 [label=AccumulateGrad]
	3043497940192 -> 3043498012272
}
